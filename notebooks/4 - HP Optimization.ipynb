{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50e5d847-b8f6-42e0-bf34-f84d24e1461c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer, AutoTokenizer, DataCollatorWithPadding, AutoModelForSequenceClassification\n",
    "from datasets import load_dataset\n",
    "from scipy.special import softmax\n",
    "import evaluate\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0001527e-3499-49c5-8722-8fb18eb9bd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset('imdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90b59df6-9e9e-44df-baec-e1e844a9f423",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8b3b456-7128-4974-8a51-a7ce3302e07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert/distilbert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cd9b6f4-dcf6-45ef-b27b-7fab6cf820c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "855214ae-ffbe-40e0-8c92-32d2724348c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(ds):\n",
    "    return tokenizer(ds[\"text\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6498b98-7095-4fcc-a8e2-bcb41774ee54",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_ds = ds.map(preprocess_text, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c6a9bdf-2d1c-48f9-a78d-fbc075bdb23c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "roc_auc = evaluate.load('roc_auc', 'binary')\n",
    "accuracy = evaluate.load('accuracy')\n",
    "f1 = evaluate.load('f1')\n",
    "precision = evaluate.load('precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53e5e7ea-2af5-4788-8170-4dad8a24359d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    pred = np.argmax(logits, axis=1)\n",
    "    probs = softmax(pred)\n",
    "    return {\n",
    "        'accuracy': accuracy.compute(predictions=pred, references=labels)['accuracy'],\n",
    "        'f1': f1.compute(predictions=pred, references=labels)['f1'],\n",
    "        'precision': precision.compute(predictions=pred, references=labels)['precision'],\n",
    "        'roc_auc': roc_auc.compute(prediction_scores=probs, references=labels)['roc_auc']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a119f5dd-6ae6-4027-beaa-eb3249677d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train = tokenized_ds[\"train\"].shuffle().select(range(1000))\n",
    "small_eval = tokenized_ds[\"test\"].shuffle().select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "316152d5-395a-41a8-99d1-489b1548f043",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"sentiment analysis model\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "607a8bb2-0927-45bf-8748-0887154693ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init(trial):\n",
    "    return AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert/distilbert-base-uncased\",\n",
    "    num_labels=2,\n",
    "    id2label=id2label, \n",
    "    label2id=label2id\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52a3e2b6-baab-4d45-a5e2-a13b6f41929a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=None,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train,\n",
    "    eval_dataset=small_eval,\n",
    "    processing_class=tokenizer,\n",
    "    model_init=model_init,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13ba38bb-4b02-462b-89e4-040e21657dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_objective(metrics):\n",
    "    combined_metric = metrics['eval_accuracy'] + metrics['eval_f1'] + metrics['eval_precision'] + metrics['eval_roc_auc']\n",
    "    loss = metrics['eval_loss']\n",
    "    return (combined_metric, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3564d617-a91f-490f-befa-55dc43885e34",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 03:17:07,693] A new study created in memory with name: no-name-f7178c36-f2b9-4f1a-955a-0f1ef2112b34\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='352' max='352' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [352/352 02:49, Epoch 11/11]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.689906</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.468085</td>\n",
       "      <td>0.663121</td>\n",
       "      <td>0.582507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.682819</td>\n",
       "      <td>0.603000</td>\n",
       "      <td>0.435277</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.613808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.672278</td>\n",
       "      <td>0.704000</td>\n",
       "      <td>0.655814</td>\n",
       "      <td>0.822157</td>\n",
       "      <td>0.709580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.655566</td>\n",
       "      <td>0.703000</td>\n",
       "      <td>0.642599</td>\n",
       "      <td>0.850318</td>\n",
       "      <td>0.709566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.629450</td>\n",
       "      <td>0.758000</td>\n",
       "      <td>0.742004</td>\n",
       "      <td>0.826603</td>\n",
       "      <td>0.760988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.594202</td>\n",
       "      <td>0.781000</td>\n",
       "      <td>0.778116</td>\n",
       "      <td>0.817021</td>\n",
       "      <td>0.782346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.563743</td>\n",
       "      <td>0.789000</td>\n",
       "      <td>0.784474</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.790628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.538617</td>\n",
       "      <td>0.802000</td>\n",
       "      <td>0.797546</td>\n",
       "      <td>0.845987</td>\n",
       "      <td>0.803677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.518485</td>\n",
       "      <td>0.808000</td>\n",
       "      <td>0.806841</td>\n",
       "      <td>0.840671</td>\n",
       "      <td>0.809139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.507491</td>\n",
       "      <td>0.815000</td>\n",
       "      <td>0.813320</td>\n",
       "      <td>0.850211</td>\n",
       "      <td>0.816250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.503879</td>\n",
       "      <td>0.816000</td>\n",
       "      <td>0.814516</td>\n",
       "      <td>0.850526</td>\n",
       "      <td>0.817217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 03:19:58,981] Trial 0 finished with values: [3.2982591473298313, 0.5038794875144958] and parameters: {'learning_rate': 2.2400641103816993e-06, 'per_device_train_batch_size': 32, 'num_train_epochs': 11}.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='176' max='176' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [176/176 12:11, Epoch 11/11]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.475457</td>\n",
       "      <td>0.807000</td>\n",
       "      <td>0.796199</td>\n",
       "      <td>0.876744</td>\n",
       "      <td>0.809738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.302014</td>\n",
       "      <td>0.881000</td>\n",
       "      <td>0.887417</td>\n",
       "      <td>0.868519</td>\n",
       "      <td>0.880079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.284385</td>\n",
       "      <td>0.894000</td>\n",
       "      <td>0.897485</td>\n",
       "      <td>0.897485</td>\n",
       "      <td>0.893877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.299801</td>\n",
       "      <td>0.898000</td>\n",
       "      <td>0.902857</td>\n",
       "      <td>0.889306</td>\n",
       "      <td>0.897337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.361596</td>\n",
       "      <td>0.897000</td>\n",
       "      <td>0.901435</td>\n",
       "      <td>0.892045</td>\n",
       "      <td>0.896506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.406447</td>\n",
       "      <td>0.891000</td>\n",
       "      <td>0.897844</td>\n",
       "      <td>0.870909</td>\n",
       "      <td>0.889751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.419184</td>\n",
       "      <td>0.896000</td>\n",
       "      <td>0.900383</td>\n",
       "      <td>0.891841</td>\n",
       "      <td>0.895539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.460134</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.891945</td>\n",
       "      <td>0.906188</td>\n",
       "      <td>0.890417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.450889</td>\n",
       "      <td>0.894000</td>\n",
       "      <td>0.898855</td>\n",
       "      <td>0.887006</td>\n",
       "      <td>0.893401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.466307</td>\n",
       "      <td>0.898000</td>\n",
       "      <td>0.900391</td>\n",
       "      <td>0.909270</td>\n",
       "      <td>0.898222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.475991</td>\n",
       "      <td>0.893000</td>\n",
       "      <td>0.894995</td>\n",
       "      <td>0.908367</td>\n",
       "      <td>0.893387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 03:32:15,500] Trial 1 finished with values: [3.58974838218208, 0.4759913384914398] and parameters: {'learning_rate': 3.807241430960454e-05, 'per_device_train_batch_size': 64, 'num_train_epochs': 11}.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:53, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.449179</td>\n",
       "      <td>0.818000</td>\n",
       "      <td>0.805970</td>\n",
       "      <td>0.897862</td>\n",
       "      <td>0.821057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 03:33:12,822] Trial 2 finished with values: [3.342889524089046, 0.4491790533065796] and parameters: {'learning_rate': 9.817558929946846e-05, 'per_device_train_batch_size': 64, 'num_train_epochs': 1}.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='352' max='352' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [352/352 02:42, Epoch 11/11]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.302007</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.895238</td>\n",
       "      <td>0.881801</td>\n",
       "      <td>0.889328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.302389</td>\n",
       "      <td>0.882000</td>\n",
       "      <td>0.893502</td>\n",
       "      <td>0.837563</td>\n",
       "      <td>0.879345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.340384</td>\n",
       "      <td>0.904000</td>\n",
       "      <td>0.908918</td>\n",
       "      <td>0.891993</td>\n",
       "      <td>0.903208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.425469</td>\n",
       "      <td>0.892000</td>\n",
       "      <td>0.897533</td>\n",
       "      <td>0.880819</td>\n",
       "      <td>0.891194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.386706</td>\n",
       "      <td>0.909000</td>\n",
       "      <td>0.912752</td>\n",
       "      <td>0.904943</td>\n",
       "      <td>0.908588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.571379</td>\n",
       "      <td>0.882000</td>\n",
       "      <td>0.878351</td>\n",
       "      <td>0.940397</td>\n",
       "      <td>0.884042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.536884</td>\n",
       "      <td>0.896000</td>\n",
       "      <td>0.900763</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.895403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.563858</td>\n",
       "      <td>0.899000</td>\n",
       "      <td>0.904447</td>\n",
       "      <td>0.885185</td>\n",
       "      <td>0.898100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.569212</td>\n",
       "      <td>0.902000</td>\n",
       "      <td>0.904483</td>\n",
       "      <td>0.911591</td>\n",
       "      <td>0.902159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.552723</td>\n",
       "      <td>0.901000</td>\n",
       "      <td>0.906161</td>\n",
       "      <td>0.888476</td>\n",
       "      <td>0.900171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.553687</td>\n",
       "      <td>0.901000</td>\n",
       "      <td>0.905983</td>\n",
       "      <td>0.889925</td>\n",
       "      <td>0.900239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 03:35:56,242] Trial 3 finished with values: [3.597146955026586, 0.5536873936653137] and parameters: {'learning_rate': 6.55504763726749e-05, 'per_device_train_batch_size': 32, 'num_train_epochs': 11}.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='192' max='192' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [192/192 01:27, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.684426</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.518614</td>\n",
       "      <td>0.770992</td>\n",
       "      <td>0.633246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.666765</td>\n",
       "      <td>0.682000</td>\n",
       "      <td>0.598485</td>\n",
       "      <td>0.861818</td>\n",
       "      <td>0.689869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.628460</td>\n",
       "      <td>0.771000</td>\n",
       "      <td>0.767040</td>\n",
       "      <td>0.809013</td>\n",
       "      <td>0.772471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.577743</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.798464</td>\n",
       "      <td>0.792381</td>\n",
       "      <td>0.789485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.545037</td>\n",
       "      <td>0.796000</td>\n",
       "      <td>0.789691</td>\n",
       "      <td>0.845475</td>\n",
       "      <td>0.797942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.530946</td>\n",
       "      <td>0.804000</td>\n",
       "      <td>0.801619</td>\n",
       "      <td>0.840764</td>\n",
       "      <td>0.805339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 03:37:24,323] Trial 4 finished with values: [3.2517227362600325, 0.5309457778930664] and parameters: {'learning_rate': 4.078883317104503e-06, 'per_device_train_batch_size': 32, 'num_train_epochs': 6}.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='176' max='176' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [176/176 13:10, Epoch 11/11]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.686561</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.240924</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.554036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.672503</td>\n",
       "      <td>0.686000</td>\n",
       "      <td>0.624402</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.692376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.645168</td>\n",
       "      <td>0.754000</td>\n",
       "      <td>0.742138</td>\n",
       "      <td>0.810069</td>\n",
       "      <td>0.756438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.591916</td>\n",
       "      <td>0.779000</td>\n",
       "      <td>0.788517</td>\n",
       "      <td>0.780303</td>\n",
       "      <td>0.778370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.537809</td>\n",
       "      <td>0.795000</td>\n",
       "      <td>0.782147</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.797928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.472642</td>\n",
       "      <td>0.828000</td>\n",
       "      <td>0.828685</td>\n",
       "      <td>0.854209</td>\n",
       "      <td>0.828822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.426518</td>\n",
       "      <td>0.843000</td>\n",
       "      <td>0.846530</td>\n",
       "      <td>0.855731</td>\n",
       "      <td>0.843193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.397719</td>\n",
       "      <td>0.854000</td>\n",
       "      <td>0.856582</td>\n",
       "      <td>0.870259</td>\n",
       "      <td>0.854376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.378967</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.863813</td>\n",
       "      <td>0.868885</td>\n",
       "      <td>0.860042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.369507</td>\n",
       "      <td>0.864000</td>\n",
       "      <td>0.866405</td>\n",
       "      <td>0.880240</td>\n",
       "      <td>0.864387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.366410</td>\n",
       "      <td>0.863000</td>\n",
       "      <td>0.865290</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.863420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 03:50:36,585] Trial 5 finished with values: [3.4717101824812726, 0.36640986800193787] and parameters: {'learning_rate': 5.482414005625026e-06, 'per_device_train_batch_size': 64, 'num_train_epochs': 11}.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='88' max='88' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [88/88 31:22, Epoch 11/11]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.684163</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.339036</td>\n",
       "      <td>0.865079</td>\n",
       "      <td>0.587818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.668731</td>\n",
       "      <td>0.671000</td>\n",
       "      <td>0.581957</td>\n",
       "      <td>0.848148</td>\n",
       "      <td>0.679027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.641009</td>\n",
       "      <td>0.755000</td>\n",
       "      <td>0.742917</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.757474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.596496</td>\n",
       "      <td>0.772000</td>\n",
       "      <td>0.757447</td>\n",
       "      <td>0.841608</td>\n",
       "      <td>0.774936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.542228</td>\n",
       "      <td>0.791000</td>\n",
       "      <td>0.789102</td>\n",
       "      <td>0.824895</td>\n",
       "      <td>0.792222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.485724</td>\n",
       "      <td>0.821000</td>\n",
       "      <td>0.826382</td>\n",
       "      <td>0.828794</td>\n",
       "      <td>0.820895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.443154</td>\n",
       "      <td>0.829000</td>\n",
       "      <td>0.826748</td>\n",
       "      <td>0.868085</td>\n",
       "      <td>0.830402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.407383</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.856597</td>\n",
       "      <td>0.846881</td>\n",
       "      <td>0.849418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.386334</td>\n",
       "      <td>0.857000</td>\n",
       "      <td>0.861568</td>\n",
       "      <td>0.862403</td>\n",
       "      <td>0.856869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.377603</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.890269</td>\n",
       "      <td>0.860995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.372389</td>\n",
       "      <td>0.865000</td>\n",
       "      <td>0.867517</td>\n",
       "      <td>0.880478</td>\n",
       "      <td>0.865354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 04:22:28,561] Trial 6 finished with values: [3.4783496109772782, 0.37238943576812744] and parameters: {'learning_rate': 9.921351154641147e-06, 'per_device_train_batch_size': 128, 'num_train_epochs': 11}.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='88' max='88' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [88/88 39:24, Epoch 11/11]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.692711</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.327731</td>\n",
       "      <td>0.593909</td>\n",
       "      <td>0.530337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.689246</td>\n",
       "      <td>0.547000</td>\n",
       "      <td>0.306279</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.559445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.686036</td>\n",
       "      <td>0.569000</td>\n",
       "      <td>0.347958</td>\n",
       "      <td>0.798611</td>\n",
       "      <td>0.581198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.683125</td>\n",
       "      <td>0.563000</td>\n",
       "      <td>0.305246</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.576280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.679468</td>\n",
       "      <td>0.618000</td>\n",
       "      <td>0.461972</td>\n",
       "      <td>0.849741</td>\n",
       "      <td>0.628587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.675850</td>\n",
       "      <td>0.651000</td>\n",
       "      <td>0.546164</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.659617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.672180</td>\n",
       "      <td>0.678000</td>\n",
       "      <td>0.601485</td>\n",
       "      <td>0.835052</td>\n",
       "      <td>0.685320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.669068</td>\n",
       "      <td>0.677000</td>\n",
       "      <td>0.596754</td>\n",
       "      <td>0.841549</td>\n",
       "      <td>0.684557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.666369</td>\n",
       "      <td>0.687000</td>\n",
       "      <td>0.616891</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.694024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.664671</td>\n",
       "      <td>0.689000</td>\n",
       "      <td>0.620269</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.695959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.664040</td>\n",
       "      <td>0.686000</td>\n",
       "      <td>0.616137</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.692989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 05:02:20,869] Trial 7 finished with values: [2.8323353170352608, 0.6640395522117615] and parameters: {'learning_rate': 3.166410590352595e-06, 'per_device_train_batch_size': 128, 'num_train_epochs': 11}.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 02:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.695483</td>\n",
       "      <td>0.448000</td>\n",
       "      <td>0.418947</td>\n",
       "      <td>0.459584</td>\n",
       "      <td>0.450220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 05:04:47,130] Trial 8 finished with values: [1.7767521188788638, 0.6954831480979919] and parameters: {'learning_rate': 1.7319189260937104e-06, 'per_device_train_batch_size': 128, 'num_train_epochs': 1}.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='176' max='176' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [176/176 09:22, Epoch 11/11]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.681681</td>\n",
       "      <td>0.581000</td>\n",
       "      <td>0.364188</td>\n",
       "      <td>0.845070</td>\n",
       "      <td>0.593280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.654125</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.691358</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.729549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.582368</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.779559</td>\n",
       "      <td>0.808732</td>\n",
       "      <td>0.780971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.491079</td>\n",
       "      <td>0.812000</td>\n",
       "      <td>0.832740</td>\n",
       "      <td>0.771005</td>\n",
       "      <td>0.808719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.404127</td>\n",
       "      <td>0.849000</td>\n",
       "      <td>0.855778</td>\n",
       "      <td>0.845283</td>\n",
       "      <td>0.848383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.354064</td>\n",
       "      <td>0.868000</td>\n",
       "      <td>0.871094</td>\n",
       "      <td>0.879684</td>\n",
       "      <td>0.868188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.330193</td>\n",
       "      <td>0.879000</td>\n",
       "      <td>0.880553</td>\n",
       "      <td>0.899194</td>\n",
       "      <td>0.879575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.318131</td>\n",
       "      <td>0.881000</td>\n",
       "      <td>0.882061</td>\n",
       "      <td>0.904472</td>\n",
       "      <td>0.881713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.306966</td>\n",
       "      <td>0.892000</td>\n",
       "      <td>0.895753</td>\n",
       "      <td>0.894027</td>\n",
       "      <td>0.891807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.304559</td>\n",
       "      <td>0.888000</td>\n",
       "      <td>0.890196</td>\n",
       "      <td>0.902584</td>\n",
       "      <td>0.888347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.303239</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.892578</td>\n",
       "      <td>0.901381</td>\n",
       "      <td>0.890213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 05:14:13,413] Trial 9 finished with values: [3.5741718819392347, 0.3032391369342804] and parameters: {'learning_rate': 7.578566728652807e-06, 'per_device_train_batch_size': 64, 'num_train_epochs': 11}.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='192' max='192' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [192/192 01:28, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.333642</td>\n",
       "      <td>0.861000</td>\n",
       "      <td>0.875560</td>\n",
       "      <td>0.815000</td>\n",
       "      <td>0.858014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.434097</td>\n",
       "      <td>0.841000</td>\n",
       "      <td>0.863519</td>\n",
       "      <td>0.776235</td>\n",
       "      <td>0.836357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.319882</td>\n",
       "      <td>0.899000</td>\n",
       "      <td>0.899101</td>\n",
       "      <td>0.929752</td>\n",
       "      <td>0.900006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.485104</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.875776</td>\n",
       "      <td>0.942094</td>\n",
       "      <td>0.882176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.359623</td>\n",
       "      <td>0.914000</td>\n",
       "      <td>0.915851</td>\n",
       "      <td>0.926733</td>\n",
       "      <td>0.914309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.356621</td>\n",
       "      <td>0.918000</td>\n",
       "      <td>0.920696</td>\n",
       "      <td>0.920696</td>\n",
       "      <td>0.917905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 05:15:42,724] Trial 10 finished with values: [3.677297748196916, 0.356621116399765] and parameters: {'learning_rate': 5.434626182268531e-05, 'per_device_train_batch_size': 32, 'num_train_epochs': 6}.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:43, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.694626</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.311927</td>\n",
       "      <td>0.483740</td>\n",
       "      <td>0.483617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 05:16:28,378] Trial 11 finished with values: [1.7542835042258504, 0.6946255564689636] and parameters: {'learning_rate': 1.975633975205553e-06, 'per_device_train_batch_size': 64, 'num_train_epochs': 1}.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 01:40, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.679974</td>\n",
       "      <td>0.619000</td>\n",
       "      <td>0.459574</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.629758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 05:18:29,386] Trial 12 finished with values: [2.570034595992968, 0.6799742579460144] and parameters: {'learning_rate': 2.25178137967719e-05, 'per_device_train_batch_size': 128, 'num_train_epochs': 1}.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='88' max='88' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [88/88 23:10, Epoch 11/11]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.683187</td>\n",
       "      <td>0.583000</td>\n",
       "      <td>0.361409</td>\n",
       "      <td>0.867647</td>\n",
       "      <td>0.595486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.665619</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.591195</td>\n",
       "      <td>0.845324</td>\n",
       "      <td>0.682759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.631940</td>\n",
       "      <td>0.761000</td>\n",
       "      <td>0.753862</td>\n",
       "      <td>0.806167</td>\n",
       "      <td>0.762868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.579357</td>\n",
       "      <td>0.782000</td>\n",
       "      <td>0.775720</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.783858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.520353</td>\n",
       "      <td>0.802000</td>\n",
       "      <td>0.795876</td>\n",
       "      <td>0.852097</td>\n",
       "      <td>0.803949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.459219</td>\n",
       "      <td>0.834000</td>\n",
       "      <td>0.840691</td>\n",
       "      <td>0.834286</td>\n",
       "      <td>0.833536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.415829</td>\n",
       "      <td>0.838000</td>\n",
       "      <td>0.836694</td>\n",
       "      <td>0.873684</td>\n",
       "      <td>0.839242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.380974</td>\n",
       "      <td>0.856000</td>\n",
       "      <td>0.861538</td>\n",
       "      <td>0.856597</td>\n",
       "      <td>0.855629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.362082</td>\n",
       "      <td>0.861000</td>\n",
       "      <td>0.865179</td>\n",
       "      <td>0.867704</td>\n",
       "      <td>0.860941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.353813</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.872047</td>\n",
       "      <td>0.887776</td>\n",
       "      <td>0.870462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.349636</td>\n",
       "      <td>0.867000</td>\n",
       "      <td>0.870244</td>\n",
       "      <td>0.877953</td>\n",
       "      <td>0.867152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 05:41:56,661] Trial 13 finished with values: [3.482349086551544, 0.3496359884738922] and parameters: {'learning_rate': 1.0645694774694843e-05, 'per_device_train_batch_size': 128, 'num_train_epochs': 11}.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='176' max='176' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [176/176 12:06, Epoch 11/11]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.692954</td>\n",
       "      <td>0.515000</td>\n",
       "      <td>0.243370</td>\n",
       "      <td>0.629032</td>\n",
       "      <td>0.527816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.689525</td>\n",
       "      <td>0.535000</td>\n",
       "      <td>0.263074</td>\n",
       "      <td>0.728070</td>\n",
       "      <td>0.548180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.685758</td>\n",
       "      <td>0.612000</td>\n",
       "      <td>0.477089</td>\n",
       "      <td>0.786667</td>\n",
       "      <td>0.621490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.682297</td>\n",
       "      <td>0.602000</td>\n",
       "      <td>0.423188</td>\n",
       "      <td>0.843931</td>\n",
       "      <td>0.613249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.678075</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.578164</td>\n",
       "      <td>0.806228</td>\n",
       "      <td>0.667367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.673562</td>\n",
       "      <td>0.687000</td>\n",
       "      <td>0.618758</td>\n",
       "      <td>0.835526</td>\n",
       "      <td>0.693888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.668915</td>\n",
       "      <td>0.699000</td>\n",
       "      <td>0.642942</td>\n",
       "      <td>0.831288</td>\n",
       "      <td>0.705153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.664963</td>\n",
       "      <td>0.695000</td>\n",
       "      <td>0.628502</td>\n",
       "      <td>0.848684</td>\n",
       "      <td>0.701897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.661131</td>\n",
       "      <td>0.707000</td>\n",
       "      <td>0.658906</td>\n",
       "      <td>0.827485</td>\n",
       "      <td>0.712618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.658801</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.662791</td>\n",
       "      <td>0.830904</td>\n",
       "      <td>0.715587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.657973</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.662791</td>\n",
       "      <td>0.830904</td>\n",
       "      <td>0.715587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 05:54:06,529] Trial 14 finished with values: [2.919281706586844, 0.6579725742340088] and parameters: {'learning_rate': 2.0213770857001143e-06, 'per_device_train_batch_size': 64, 'num_train_epochs': 11}.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='96' max='96' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [96/96 07:30, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.685626</td>\n",
       "      <td>0.548000</td>\n",
       "      <td>0.266234</td>\n",
       "      <td>0.828283</td>\n",
       "      <td>0.561705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.671288</td>\n",
       "      <td>0.691000</td>\n",
       "      <td>0.635183</td>\n",
       "      <td>0.815152</td>\n",
       "      <td>0.697008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.648140</td>\n",
       "      <td>0.748000</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.803204</td>\n",
       "      <td>0.750431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.616103</td>\n",
       "      <td>0.756000</td>\n",
       "      <td>0.737634</td>\n",
       "      <td>0.830508</td>\n",
       "      <td>0.759258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.589907</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.807453</td>\n",
       "      <td>0.780903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.580093</td>\n",
       "      <td>0.777000</td>\n",
       "      <td>0.770340</td>\n",
       "      <td>0.823789</td>\n",
       "      <td>0.778886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 06:01:39,932] Trial 15 finished with values: [3.1500147947441763, 0.5800926089286804] and parameters: {'learning_rate': 6.125672944184742e-06, 'per_device_train_batch_size': 64, 'num_train_epochs': 6}.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='176' max='176' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [176/176 16:22, Epoch 11/11]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.672500</td>\n",
       "      <td>0.643000</td>\n",
       "      <td>0.512960</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.652833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.600798</td>\n",
       "      <td>0.755000</td>\n",
       "      <td>0.726257</td>\n",
       "      <td>0.859788</td>\n",
       "      <td>0.759448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.468402</td>\n",
       "      <td>0.816000</td>\n",
       "      <td>0.804671</td>\n",
       "      <td>0.891765</td>\n",
       "      <td>0.818919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.353727</td>\n",
       "      <td>0.866000</td>\n",
       "      <td>0.873823</td>\n",
       "      <td>0.851376</td>\n",
       "      <td>0.864892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.311244</td>\n",
       "      <td>0.884000</td>\n",
       "      <td>0.886051</td>\n",
       "      <td>0.900200</td>\n",
       "      <td>0.884410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.293748</td>\n",
       "      <td>0.889000</td>\n",
       "      <td>0.893780</td>\n",
       "      <td>0.884470</td>\n",
       "      <td>0.888497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.289445</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.898354</td>\n",
       "      <td>0.899225</td>\n",
       "      <td>0.894913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.308582</td>\n",
       "      <td>0.879000</td>\n",
       "      <td>0.878636</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.880119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.289555</td>\n",
       "      <td>0.892000</td>\n",
       "      <td>0.895349</td>\n",
       "      <td>0.897087</td>\n",
       "      <td>0.891943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.291608</td>\n",
       "      <td>0.887000</td>\n",
       "      <td>0.890185</td>\n",
       "      <td>0.894531</td>\n",
       "      <td>0.887039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.291608</td>\n",
       "      <td>0.889000</td>\n",
       "      <td>0.892546</td>\n",
       "      <td>0.893411</td>\n",
       "      <td>0.888906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 06:18:06,884] Trial 16 finished with values: [3.5638624101327228, 0.29160797595977783] and parameters: {'learning_rate': 1.0980482854026251e-05, 'per_device_train_batch_size': 64, 'num_train_epochs': 11}.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='176' max='176' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [176/176 14:33, Epoch 11/11]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.634682</td>\n",
       "      <td>0.703000</td>\n",
       "      <td>0.631970</td>\n",
       "      <td>0.879310</td>\n",
       "      <td>0.710383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.418919</td>\n",
       "      <td>0.826000</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.865672</td>\n",
       "      <td>0.827433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.314344</td>\n",
       "      <td>0.878000</td>\n",
       "      <td>0.881553</td>\n",
       "      <td>0.884990</td>\n",
       "      <td>0.877995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.292410</td>\n",
       "      <td>0.886000</td>\n",
       "      <td>0.887574</td>\n",
       "      <td>0.905433</td>\n",
       "      <td>0.886549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.297020</td>\n",
       "      <td>0.889000</td>\n",
       "      <td>0.891496</td>\n",
       "      <td>0.901186</td>\n",
       "      <td>0.889246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.304756</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.895038</td>\n",
       "      <td>0.883239</td>\n",
       "      <td>0.889396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.335184</td>\n",
       "      <td>0.893000</td>\n",
       "      <td>0.895201</td>\n",
       "      <td>0.906746</td>\n",
       "      <td>0.893319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.358331</td>\n",
       "      <td>0.896000</td>\n",
       "      <td>0.897233</td>\n",
       "      <td>0.917172</td>\n",
       "      <td>0.896629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.365698</td>\n",
       "      <td>0.892000</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.901768</td>\n",
       "      <td>0.892147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.373565</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.892996</td>\n",
       "      <td>0.898239</td>\n",
       "      <td>0.890077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.376929</td>\n",
       "      <td>0.892000</td>\n",
       "      <td>0.894325</td>\n",
       "      <td>0.904950</td>\n",
       "      <td>0.892283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 06:32:44,605] Trial 17 finished with values: [3.5835588279810042, 0.37692877650260925] and parameters: {'learning_rate': 1.947056541725573e-05, 'per_device_train_batch_size': 64, 'num_train_epochs': 11}.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 17:00, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.694192</td>\n",
       "      <td>0.488000</td>\n",
       "      <td>0.375610</td>\n",
       "      <td>0.508251</td>\n",
       "      <td>0.494692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.692226</td>\n",
       "      <td>0.529000</td>\n",
       "      <td>0.330014</td>\n",
       "      <td>0.623656</td>\n",
       "      <td>0.539722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.690744</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.311377</td>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.551926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.689741</td>\n",
       "      <td>0.532000</td>\n",
       "      <td>0.254777</td>\n",
       "      <td>0.720721</td>\n",
       "      <td>0.545278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.689004</td>\n",
       "      <td>0.541000</td>\n",
       "      <td>0.281690</td>\n",
       "      <td>0.737705</td>\n",
       "      <td>0.553914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.688736</td>\n",
       "      <td>0.543000</td>\n",
       "      <td>0.284820</td>\n",
       "      <td>0.745902</td>\n",
       "      <td>0.555917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 06:50:07,706] Trial 18 finished with values: [2.1296383102785854, 0.6887364983558655] and parameters: {'learning_rate': 2.069941910959875e-06, 'per_device_train_batch_size': 128, 'num_train_epochs': 6}.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 14:30, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.694981</td>\n",
       "      <td>0.457000</td>\n",
       "      <td>0.394649</td>\n",
       "      <td>0.465789</td>\n",
       "      <td>0.461035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.693584</td>\n",
       "      <td>0.502000</td>\n",
       "      <td>0.353247</td>\n",
       "      <td>0.537549</td>\n",
       "      <td>0.510410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.692560</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.591133</td>\n",
       "      <td>0.530133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.691879</td>\n",
       "      <td>0.526000</td>\n",
       "      <td>0.286145</td>\n",
       "      <td>0.646259</td>\n",
       "      <td>0.538046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.691404</td>\n",
       "      <td>0.532000</td>\n",
       "      <td>0.293051</td>\n",
       "      <td>0.668966</td>\n",
       "      <td>0.544121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.691234</td>\n",
       "      <td>0.533000</td>\n",
       "      <td>0.293495</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.545156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 07:04:58,858] Trial 19 finished with values: [2.0452620166714035, 0.69123375415802] and parameters: {'learning_rate': 1.44356019589745e-06, 'per_device_train_batch_size': 128, 'num_train_epochs': 6}.\n"
     ]
    }
   ],
   "source": [
    "def optuna_hp_space(trial):\n",
    "    return {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-6, 1e-4, log=True),\n",
    "        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [32, 64, 128]),\n",
    "        'num_train_epochs': trial.suggest_int('num_train_epochs', 1, 11, step=5)\n",
    "    }\n",
    "\n",
    "best_trials = trainer.hyperparameter_search(\n",
    "    direction=['maximize', 'minimize'],\n",
    "    backend=\"optuna\",\n",
    "    hp_space=optuna_hp_space,\n",
    "    n_trials=20,\n",
    "    compute_objective=compute_objective\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f63a6751-25fa-46ba-85dd-a31a5e044ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:04, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.678391</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.633663</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.632878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.708419</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.643517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.63, 'f1': 0.6336633663366337, 'precision': 0.5925925925925926, 'roc_auc': 0.6328783621035728}\n",
      "{'accuracy': 0.64, 'f1': 0.6470588235294118, 'precision': 0.6, 'roc_auc': 0.6435166599759132}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=14, training_loss=0.2708761351449149, metrics={'train_runtime': 5.248, 'train_samples_per_second': 38.11, 'train_steps_per_second': 2.668, 'total_flos': 25946016810192.0, 'train_loss': 0.2708761351449149, 'epoch': 2.0})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "91f29b1b-21ce-4842-a465-05fbd237b0e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mresults\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2ad4786-520c-475a-8708-5b0acd55af4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:12, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.661977</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.393443</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.650482</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.607595</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits [[-0.04660358 -0.23375049]\n",
      " [-0.13670678 -0.10802048]\n",
      " [ 0.04001261 -0.23190552]\n",
      " [ 0.05575487 -0.23637293]\n",
      " [-0.0457897  -0.15124926]\n",
      " [-0.05000955 -0.17469226]\n",
      " [-0.15288801 -0.11614197]\n",
      " [-0.01152636 -0.21166293]\n",
      " [-0.00869801 -0.15249668]\n",
      " [-0.08077078 -0.14809582]\n",
      " [-0.05842046 -0.17459695]\n",
      " [ 0.0862514  -0.28164783]\n",
      " [ 0.05259624 -0.25397056]\n",
      " [-0.0023636  -0.28595626]\n",
      " [-0.06346934 -0.11055364]\n",
      " [ 0.04421073 -0.18892325]\n",
      " [-0.04360927 -0.25736746]\n",
      " [ 0.03814324 -0.2788692 ]\n",
      " [ 0.01327825 -0.18881446]\n",
      " [-0.09355123 -0.17405675]\n",
      " [-0.03577552 -0.25836244]\n",
      " [ 0.05434755 -0.27062386]\n",
      " [ 0.01273063 -0.21328023]\n",
      " [-0.14728864 -0.13143681]\n",
      " [ 0.11737015 -0.30923447]\n",
      " [-0.17709984 -0.07700922]\n",
      " [-0.06231025 -0.21241571]\n",
      " [ 0.05190599 -0.27577394]\n",
      " [-0.10867372 -0.11169931]\n",
      " [-0.12813894 -0.07832247]\n",
      " [-0.19858006 -0.12412699]\n",
      " [-0.00064888 -0.27195218]\n",
      " [ 0.0068058  -0.17954671]\n",
      " [-0.0189494  -0.2326941 ]\n",
      " [-0.03986066 -0.13679364]\n",
      " [-0.04122387 -0.15880439]\n",
      " [-0.06984933 -0.20183553]\n",
      " [-0.03367601 -0.18643823]\n",
      " [ 0.12475201 -0.32294258]\n",
      " [ 0.06792117 -0.25735727]\n",
      " [-0.07026118 -0.19789124]\n",
      " [ 0.16503318 -0.26590857]\n",
      " [ 0.17976631 -0.3676163 ]\n",
      " [ 0.16458142 -0.28284094]\n",
      " [-0.06169243 -0.14872222]\n",
      " [-0.0009573  -0.223579  ]\n",
      " [-0.05349043 -0.20263003]\n",
      " [ 0.09023724 -0.21688735]\n",
      " [-0.09331644 -0.1526622 ]\n",
      " [-0.15654361 -0.07550434]\n",
      " [ 0.01037706 -0.11714473]\n",
      " [ 0.04046692 -0.2685526 ]\n",
      " [-0.06444433 -0.1711637 ]\n",
      " [-0.12865087 -0.13723177]\n",
      " [-0.09340946 -0.11667739]\n",
      " [ 0.01480255 -0.25268388]\n",
      " [ 0.05514786 -0.2502244 ]\n",
      " [-0.19868794 -0.08492787]\n",
      " [ 0.02384846 -0.17827937]\n",
      " [ 0.12817304 -0.31327236]\n",
      " [ 0.17560637 -0.36605904]\n",
      " [ 0.05697376 -0.21451743]\n",
      " [-0.02434826 -0.23766488]\n",
      " [-0.09159756 -0.15233141]\n",
      " [-0.07876568 -0.12477667]\n",
      " [ 0.07259153 -0.3023741 ]\n",
      " [ 0.06997382 -0.30699053]\n",
      " [-0.05901697 -0.15782301]\n",
      " [ 0.03266672 -0.23824495]\n",
      " [ 0.06792194 -0.247083  ]\n",
      " [ 0.00292984 -0.22619952]\n",
      " [-0.01629615 -0.27548862]\n",
      " [ 0.04578934 -0.2597234 ]\n",
      " [-0.04069917 -0.18559042]\n",
      " [ 0.11835676 -0.28335854]\n",
      " [ 0.02379316 -0.22294486]\n",
      " [ 0.15298794 -0.32705697]\n",
      " [ 0.02945263 -0.22784673]\n",
      " [-0.04682411 -0.21858309]\n",
      " [-0.09905037 -0.13129759]\n",
      " [ 0.02533056 -0.27853522]\n",
      " [-0.118131   -0.14342482]\n",
      " [ 0.01304299 -0.2648308 ]\n",
      " [-0.21246484 -0.05083919]\n",
      " [-0.13203436 -0.09668572]\n",
      " [-0.10846673 -0.13440341]\n",
      " [-0.1993865  -0.07809178]\n",
      " [-0.00510473 -0.19710556]\n",
      " [ 0.12755693 -0.3353465 ]\n",
      " [-0.12759253 -0.12551747]\n",
      " [-0.12736513 -0.15724902]\n",
      " [ 0.00747069 -0.24761602]\n",
      " [-0.05364028 -0.21198568]\n",
      " [-0.12942804 -0.04107048]\n",
      " [-0.11002176 -0.13634427]\n",
      " [-0.10188618 -0.15710516]\n",
      " [ 0.05784356 -0.274651  ]\n",
      " [ 0.09773505 -0.25135988]\n",
      " [ 0.1360613  -0.27342924]\n",
      " [-0.09199991 -0.06398914]]\n",
      "labels [1 1 0 1 0 1 1 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 0 1 0 1 0 1 1 1 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 0 0 0 0 1 0 0 1 1 0 0 0 0 1\n",
      " 0 0 0 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 0 1 0 0 0 0 1 1]\n",
      "pred [0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1]\n",
      "prob [0.00806088 0.02191174 0.00806088 0.00806088 0.00806088 0.00806088\n",
      " 0.02191174 0.00806088 0.00806088 0.00806088 0.00806088 0.00806088\n",
      " 0.00806088 0.00806088 0.00806088 0.00806088 0.00806088 0.00806088\n",
      " 0.00806088 0.00806088 0.00806088 0.00806088 0.00806088 0.02191174\n",
      " 0.00806088 0.02191174 0.00806088 0.00806088 0.00806088 0.02191174\n",
      " 0.02191174 0.00806088 0.00806088 0.00806088 0.00806088 0.00806088\n",
      " 0.00806088 0.00806088 0.00806088 0.00806088 0.00806088 0.00806088\n",
      " 0.00806088 0.00806088 0.00806088 0.00806088 0.00806088 0.00806088\n",
      " 0.00806088 0.02191174 0.00806088 0.00806088 0.00806088 0.00806088\n",
      " 0.00806088 0.00806088 0.00806088 0.02191174 0.00806088 0.00806088\n",
      " 0.00806088 0.00806088 0.00806088 0.00806088 0.00806088 0.00806088\n",
      " 0.00806088 0.00806088 0.00806088 0.00806088 0.00806088 0.00806088\n",
      " 0.00806088 0.00806088 0.00806088 0.00806088 0.00806088 0.00806088\n",
      " 0.00806088 0.00806088 0.00806088 0.00806088 0.00806088 0.02191174\n",
      " 0.02191174 0.00806088 0.02191174 0.00806088 0.00806088 0.02191174\n",
      " 0.00806088 0.00806088 0.00806088 0.02191174 0.00806088 0.00806088\n",
      " 0.00806088 0.00806088 0.00806088 0.02191174]\n",
      "logits [[-0.09205364 -0.21578547]\n",
      " [-0.23841968 -0.0344746 ]\n",
      " [ 0.01544126 -0.21057345]\n",
      " [ 0.03421563 -0.19934468]\n",
      " [-0.09657516 -0.09302739]\n",
      " [-0.10595549 -0.11427231]\n",
      " [-0.24340639 -0.0280476 ]\n",
      " [-0.03437927 -0.18392354]\n",
      " [-0.04196286 -0.09446843]\n",
      " [-0.1638285  -0.07385499]\n",
      " [-0.11299454 -0.12925076]\n",
      " [ 0.08152131 -0.27815998]\n",
      " [ 0.03877581 -0.22311415]\n",
      " [-0.03551977 -0.26939753]\n",
      " [-0.1177394  -0.04125257]\n",
      " [ 0.00630401 -0.15181382]\n",
      " [-0.07189154 -0.23855215]\n",
      " [ 0.01431189 -0.2553445 ]\n",
      " [-0.01991373 -0.13562633]\n",
      " [-0.17505188 -0.09508034]\n",
      " [-0.06832414 -0.21507362]\n",
      " [ 0.04332456 -0.2632925 ]\n",
      " [-0.01736506 -0.19686358]\n",
      " [-0.23777093 -0.05334592]\n",
      " [ 0.14585972 -0.30986142]\n",
      " [-0.27253017  0.0056341 ]\n",
      " [-0.10267121 -0.16968845]\n",
      " [ 0.03642937 -0.25707445]\n",
      " [-0.19925159 -0.01819357]\n",
      " [-0.22043526  0.01215815]\n",
      " [-0.29094315 -0.04387819]\n",
      " [-0.03984843 -0.24181311]\n",
      " [-0.03854002 -0.12998979]\n",
      " [-0.05274809 -0.19869809]\n",
      " [-0.08801797 -0.08875647]\n",
      " [-0.10731798 -0.09359359]\n",
      " [-0.13527094 -0.14825381]\n",
      " [-0.07106694 -0.14981832]\n",
      " [ 0.12730922 -0.32309628]\n",
      " [ 0.05194038 -0.22158915]\n",
      " [-0.11529022 -0.1587644 ]\n",
      " [ 0.18223505 -0.25285974]\n",
      " [ 0.20746551 -0.3889367 ]\n",
      " [ 0.16366959 -0.27658543]\n",
      " [-0.12300871 -0.09245928]\n",
      " [-0.04109155 -0.18134268]\n",
      " [-0.099493   -0.17467602]\n",
      " [ 0.07706185 -0.18557341]\n",
      " [-0.15666203 -0.09080317]\n",
      " [-0.24118775  0.01779298]\n",
      " [-0.03396066 -0.06058563]\n",
      " [ 0.01872756 -0.24447209]\n",
      " [-0.1130956  -0.13378616]\n",
      " [-0.20314555 -0.05571713]\n",
      " [-0.1691979  -0.03934381]\n",
      " [-0.02193789 -0.21677451]\n",
      " [ 0.0434155  -0.23200554]\n",
      " [-0.28667486 -0.00474239]\n",
      " [-0.02186914 -0.14980806]\n",
      " [ 0.14253396 -0.31526637]\n",
      " [ 0.20619844 -0.3835151 ]\n",
      " [ 0.02542784 -0.19153713]\n",
      " [-0.0608859  -0.20311493]\n",
      " [-0.16123801 -0.090362  ]\n",
      " [-0.15287544 -0.05507892]\n",
      " [ 0.06013514 -0.29303208]\n",
      " [ 0.06568191 -0.29720485]\n",
      " [-0.11475206 -0.11486989]\n",
      " [ 0.01459849 -0.21365894]\n",
      " [ 0.05432511 -0.22450157]\n",
      " [-0.0210603  -0.19667388]\n",
      " [-0.04405512 -0.25698847]\n",
      " [ 0.04284643 -0.23600075]\n",
      " [-0.09011141 -0.1373895 ]\n",
      " [ 0.12585905 -0.26889005]\n",
      " [ 0.01211846 -0.19115534]\n",
      " [ 0.17256704 -0.3376569 ]\n",
      " [ 0.00356211 -0.19473748]\n",
      " [-0.09883499 -0.18239832]\n",
      " [-0.18025336 -0.06443709]\n",
      " [ 0.01774974 -0.2725014 ]\n",
      " [-0.19240573 -0.07760947]\n",
      " [-0.03370661 -0.23216322]\n",
      " [-0.33015314  0.03645187]\n",
      " [-0.19923924 -0.00885594]\n",
      " [-0.18816552 -0.06252448]\n",
      " [-0.29668096 -0.00235654]\n",
      " [-0.03427605 -0.15426728]\n",
      " [ 0.15555404 -0.3577956 ]\n",
      " [-0.22102135 -0.0529262 ]\n",
      " [-0.18335558 -0.10344719]\n",
      " [-0.02617623 -0.22208178]\n",
      " [-0.09489896 -0.16730204]\n",
      " [-0.2235106   0.0496752 ]\n",
      " [-0.1918785  -0.05396112]\n",
      " [-0.15842083 -0.10795486]\n",
      " [ 0.05688009 -0.25609866]\n",
      " [ 0.08316293 -0.22721788]\n",
      " [ 0.156357   -0.27760667]\n",
      " [-0.18189637  0.02113558]]\n",
      "labels [1 1 0 1 0 1 1 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 0 1 0 1 0 1 1 1 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 0 0 0 0 1 0 0 1 1 0 0 0 0 1\n",
      " 0 0 0 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 0 1 0 0 0 0 1 1]\n",
      "pred [0 1 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 1 1 1 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 1 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 1 0 1 1 1 1 0 0 1 1 0 0 1 1 1 0 0 0 1]\n",
      "prob [0.00645224 0.017539   0.00645224 0.00645224 0.017539   0.00645224\n",
      " 0.017539   0.00645224 0.00645224 0.017539   0.00645224 0.00645224\n",
      " 0.00645224 0.00645224 0.017539   0.00645224 0.00645224 0.00645224\n",
      " 0.00645224 0.017539   0.00645224 0.00645224 0.00645224 0.017539\n",
      " 0.00645224 0.017539   0.00645224 0.00645224 0.017539   0.017539\n",
      " 0.017539   0.00645224 0.00645224 0.00645224 0.00645224 0.017539\n",
      " 0.00645224 0.00645224 0.00645224 0.00645224 0.00645224 0.00645224\n",
      " 0.00645224 0.00645224 0.017539   0.00645224 0.00645224 0.00645224\n",
      " 0.017539   0.017539   0.00645224 0.00645224 0.00645224 0.017539\n",
      " 0.017539   0.00645224 0.00645224 0.017539   0.00645224 0.00645224\n",
      " 0.00645224 0.00645224 0.00645224 0.017539   0.017539   0.00645224\n",
      " 0.00645224 0.00645224 0.00645224 0.00645224 0.00645224 0.00645224\n",
      " 0.00645224 0.00645224 0.00645224 0.00645224 0.00645224 0.00645224\n",
      " 0.00645224 0.017539   0.00645224 0.017539   0.00645224 0.017539\n",
      " 0.017539   0.017539   0.017539   0.00645224 0.00645224 0.017539\n",
      " 0.017539   0.00645224 0.00645224 0.017539   0.017539   0.017539\n",
      " 0.00645224 0.00645224 0.00645224 0.017539  ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=14, training_loss=0.6314302171979632, metrics={'train_runtime': 13.1854, 'train_samples_per_second': 15.168, 'train_steps_per_second': 1.062, 'total_flos': 25946016810192.0, 'train_loss': 0.6314302171979632, 'epoch': 2.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "083b8b80-3d37-4930-8ff5-84dc7977edbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.75}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Fake example\n",
    "pred = np.array([0, 1, 1, 0])\n",
    "labels = np.array([0, 1, 0, 0])\n",
    "\n",
    "result = accuracy.compute(predictions=pred, references=labels)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b113a77-7fec-4227-9fc5-758caa324944",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
